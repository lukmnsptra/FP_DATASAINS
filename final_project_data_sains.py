# -*- coding: utf-8 -*-
"""final_project_data_sains.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12_1rvf6U0S1fU5bNqbmjLw_MGWaq-byS

Pengumpulan Data dan Pra-pemrosesan
"""

# LINK DATASET ADA DIPALING BAWAH


# STEP 1: Import Library
# =============================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder

# Visualisasi interaktif (opsional)
# %matplotlib inline

# =============================
# STEP 2: Load Dataset
# =============================
# Jika kamu sudah upload langsung ke Colab:
df = pd.read_csv('HRDataset_v14.csv')

# Tampilkan 5 baris pertama
df.head()

# =============================
# STEP 3: Eksplorasi Awal
# =============================
# Struktur dataset
df.info()

# Cek nilai kosong
print("\nMissing Values per Kolom:\n", df.isnull().sum())

# Statistik deskriptif
df.describe(include='all')

# =============================
# STEP 4: Data Cleaning
# =============================

# Drop kolom identifier yang tidak dibutuhkan
df.drop(['Employee_Name', 'EmpID'], axis=1, inplace=True)

# Ubah format tanggal
df['LastPerformanceReview_Date'] = pd.to_datetime(df['LastPerformanceReview_Date'], errors='coerce')

# Drop baris dengan nilai kosong pada kolom penting
df = df.dropna(subset=['PerformanceScore', 'EngagementSurvey'])

# Isian nilai kosong lain dengan forward fill (atau bisa juga median)
df.fillna(method='ffill', inplace=True)

# =============================
# STEP 5: Label Encoding (kolom kategorikal)
# =============================
# Encode semua kolom kategorikal
le = LabelEncoder()
cat_cols = df.select_dtypes(include='object').columns

for col in cat_cols:
    df[col] = le.fit_transform(df[col].astype(str))

# =============================
# STEP 6: Feature Engineering
# =============================

# Tambahkan kolom HighPerformer berdasarkan PerfScoreID
df['HighPerformer'] = (df['PerfScoreID'] >= 4).astype(int)

# Tambahkan kolom LateRisk (karyawan sering absen)
df['LateRisk'] = (df['Absences'] > 10).astype(int)

# Optional: Normalisasi kolom numerik jika diperlukan (nanti di tahap 2 modeling)

# =============================
# STEP 7: Exploratory Data Analysis (EDA)
# =============================

# Plot distribusi Performance Score
sns.countplot(data=df, x='PerformanceScore')
plt.title("Distribusi Performance Score")
plt.show()

# Heatmap korelasi fitur numerik
plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Korelasi Antar Fitur")
plt.show()

# Hubungan Engagement Survey dan High Performer
sns.boxplot(data=df, x='HighPerformer', y='EngagementSurvey')
plt.title("Engagement Survey vs High Performer")
plt.show()

"""Pemodelan dan Pembelajaran Mesin"""

HighPerformer (0 = Bukan Performer Tinggi, 1 = Performer Tinggi)

"""HighPerformer (0 = Bukan Performer Tinggi, 1 = Performer Tinggi)"""

from sklearn.model_selection import train_test_split

# Pastikan PerformanceScore juga tidak masuk ke dalam X
X = df.drop(['HighPerformer', 'PerformanceScore'], axis=1)
y = df['HighPerformer']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Ukuran data training (X_train, y_train):", X_train.shape, y_train.shape)
print("Ukuran data testing (X_test, y_test):", X_test.shape, y_test.shape)

# =============================
# STEP 1: Import Library Model
# =============================
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix

# =============================
# STEP 2: Inisialisasi & Training Model
# =============================

# Drop the date column before training
X_train_numeric = X_train.drop('LastPerformanceReview_Date', axis=1)
X_test_numeric = X_test.drop('LastPerformanceReview_Date', axis=1)

# Model 1: Random Forest
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train_numeric, y_train)
y_pred_rf = rf_model.predict(X_test_numeric)

# Model 2: Logistic Regression
lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train_numeric, y_train)
y_pred_lr = lr_model.predict(X_test_numeric)

# Model 3: Decision Tree
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_numeric, y_train)
y_pred_dt = dt_model.predict(X_test_numeric)

# Execute the cell to split the data
# This cell was previously added but not executed.
from sklearn.model_selection import train_test_split

# Pisahkan fitur (X) dan target (y)
X = df.drop('HighPerformer', axis=1)
y = df['HighPerformer']

# Bagi data menjadi training dan testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Ukuran data training (X_train, y_train):", X_train.shape, y_train.shape)
print("Ukuran data testing (X_test, y_test):", X_test.shape, y_test.shape)

# =============================
# STEP 3: Evaluasi Semua Model
# =============================

def evaluate_model(name, y_true, y_pred):
    print(f"=== {name} ===")
    print("Akurasi:", accuracy_score(y_true, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(y_true, y_pred))
    print("Classification Report:\n", classification_report(y_true, y_pred))
    print("-" * 50)

evaluate_model("Random Forest", y_test, y_pred_rf)
evaluate_model("Logistic Regression", y_test, y_pred_lr)
evaluate_model("Decision Tree", y_test, y_pred_dt)

# =============================
# STEP 4: Visualisasi Feature Importance (Random Forest)
# =============================
import matplotlib.pyplot as plt
import seaborn as sns

feature_importance = pd.DataFrame({
    'Feature': X_train_numeric.columns,
    'Importance': rf_model.feature_importances_
}).sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(data=feature_importance.head(10), x='Importance', y='Feature')
plt.title("Top 10 Fitur Penting - Random Forest")
plt.show()

"""Validasi dan Evaluasi Model"""

X = df.drop(['HighPerformer', 'PerformanceScore', 'PerfScoreID'], axis=1)

# Cek kolom bertipe datetime
datetime_cols = X.select_dtypes(include=['datetime64']).columns
print("Kolom datetime yang akan di-drop:", datetime_cols)

# Drop kolom datetime sebelum training
X = X.drop(columns=datetime_cols)

# Split ulang setelah drop datetime
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Fit model ulang
rf_model.fit(X_train, y_train)

cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')

print("Akurasi per Fold (Cross Validation):", cv_scores)
print("Rata-rata Akurasi:", cv_scores.mean())

from sklearn.metrics import roc_auc_score, roc_curve
import matplotlib.pyplot as plt

# Prediksi probabilitas kelas positif
y_prob = rf_model.predict_proba(X_test)[:, 1]

# Hitung AUC
roc_auc = roc_auc_score(y_test, y_prob)
print("ROC AUC Score:", roc_auc)

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_prob)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc:.2f}", color="blue")
plt.plot([0, 1], [0, 1], "k--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve - Random Forest")
plt.legend(loc="lower right")
plt.grid()
plt.show()

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report

# Confusion matrix
y_pred = rf_model.predict(X_test)
cm = confusion_matrix(y_test, y_pred)

# Display matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.title("Confusion Matrix - Random Forest")
plt.show()

# Classification Report
print("Classification Report:\n", classification_report(y_test, y_pred))

"""Penerapan"""

# Simpan nama kolom fitur yang dipakai untuk training
joblib.dump(X_train.columns.tolist(), 'feature_columns.pkl')

import joblib

# Simpan model ke file
joblib.dump(rf_model, 'model_rf.pkl')

# LINK DATASET DARI KAGGLE
# https://www.kaggle.com/datasets/rhuebner/human-resources-data-set